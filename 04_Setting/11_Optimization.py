import numpy as np
import matplotlib.pyplot as plt

# =================================================================
# 1. 데이터 준비
# =================================================================
# y = 2 * x 관계를 가지는 간단한 데이터.
# 여기서 우리가 찾으려는 '좋은 W'의 정답은 '2'임.
X = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])


# =================================================================
# 2. 손실 함수 (Loss Function) 정의
# =================================================================
# "좋은 W를 갖는다는 것이 무엇을 의미하는가?" -> 손실이 작은 W를 갖는다는 의미.
# 모델의 예측이 얼마나 틀렸는지(손실)를 계산하는 함수.
# 평균 제곱 오차(Mean Squared Error)를 사용함.
def calculate_loss(y_pred, y_true): 
    return np.mean((y_pred - y_true) ** 2)


# =================================================================
# 3. 최적화 (Optimization) 과정
# =================================================================
# "임의의 W로 시작하여 손실을 최소화하는 W 찾기"
# 임의의 W로 시작 (예: 0)
W = 0.0

# 학습률 (W를 한 번에 얼마나 업데이트할지)
learning_rate = 0.01
# 반복 횟수
epochs = 20

print("--------- 최적화 시작 ---------")

# 반복적으로 W를 업데이트하며 손실을 줄여나감
for i in range(epochs):
    # 현재 W로 예측값을 계산함
    y_pred = W * X

    # 현재 W가 얼마나 '나쁜지' 손실 함수로 계산함
    loss = calculate_loss(y_pred, y)

    # 손실을 줄이는 방향(그래디언트)을 계산함
    gradient = np.mean(2 * X * (y_pred - y))

    # W를 손실이 줄어드는 방향으로 조금 업데이트함
    W = W - learning_rate * gradient

    # 매 단계마다 결과 출력
    print(f"Epoch {i+1:2d}: W = {W:.4f}, Loss = {loss:.4f}")

print("--------- 최적화 종료 ---------")
print(f"\n찾아낸 최적의 W: {W:.4f}")

# =================================================================
# 4. 결과 시각화
# =================================================================
plt.figure(figsize=(8, 6))
# 원본 데이터를 점으로 찍음
plt.scatter(X, y, label="Original Data")
# 최적화로 찾아낸 W를 이용해 직선을 그림
plt.plot(X, W * X, color="red", label=f"Predicted Line (W={W:.2f})")
plt.title("Optimization Result")
plt.xlabel("X")
plt.ylabel("y")
plt.legend()
plt.grid(True)
plt.show()
